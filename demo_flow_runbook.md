# ğŸ“˜ Demo Flow â€” GraphQL Data Product Runtime

This markdown captures the **end-to-end demo flow** for the Telecom Data Product runtime â€” from spec to live API, complete with narrative points that can be spoken during a demo session.

---

## âš™ï¸ Setup & Prerequisites

Before running the demo, ensure the following setup is complete:

### ğŸ§¾ 1ï¸âƒ£ Environment configuration
Create a `.env` file in your project root with these variables:
```bash
DATABRICKS_SERVER_HOSTNAME=<your-databricks-host>
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/<warehouse-id>
DATABRICKS_TOKEN=dapi<your-token>
CATALOG=india_dataengineer_recruitment
SCHEMA=telco_silver
API_KEY=dev-key
TENANT=telecom
STAGE=dev
```

### ğŸ§© 2ï¸âƒ£ Python environment
Install dependencies:
```bash
pip install -r requirements.txt
```
If missing `fastapi` or `ariadne` during later steps, install them directly:
```bash
pip install fastapi ariadne uvicorn python-dotenv databricks-sql-connector
```

### ğŸ§° 3ï¸âƒ£ Databricks connectivity test
Confirm your `.env` variables work:
```bash
python - <<'PY'
from databricks import sql
import os
conn = sql.connect(
    server_hostname=os.environ['DATABRICKS_SERVER_HOSTNAME'],
    http_path=os.environ['DATABRICKS_HTTP_PATH'],
    access_token=os.environ['DATABRICKS_TOKEN']
)
cur = conn.cursor()
cur.execute('SELECT current_user(), current_catalog(), current_schema()')
print(cur.fetchall())
cur.close(); conn.close()
PY
```
âœ… Expect your Databricks username and schema details printed.

### ğŸ§± 4ï¸âƒ£ (Optional) Start mock MCP server
If you donâ€™t have a live MCP server, run the local mock one:
```bash
python scripts/mock_mcp.py &
```
Expected output: `ğŸš€ Mock MCP server running on http://127.0.0.1:9000`

Now youâ€™re ready for the full demo run.

---

## ğŸ¯ Goal
Show how a single product spec (e.g., `dp/telecom.yml`) can automatically generate:
- a runtime registry â†’
- GraphQL API â†’
- OpenAPI & SDL contracts â†’
- and register them with an MCP/Agent registry for discovery.

No manual coding per product.

---

## ğŸ§  High-Level Narrative
> â€œOur Data Product APIs are generated and deployed fully from metadata â€” no boilerplate code. The system reads a YAML spec, builds GraphQL schema and resolvers dynamically, connects to Databricks SQL, and exports contracts that can be registered with any agent or MCP for discovery.â€

---

## ğŸ§© Step-by-Step Demo Flow

### 1ï¸âƒ£ Generate registry and schema
```bash
make regen
```
**Purpose:** Converts `dp/telecom.yml` â†’ runtime metadata (`registry/*.yaml`) and validates stitched SDL (GraphQL schema).

**Talking point:** â€œFrom the product spec, we automatically infer entities, relationships, and filters â€” these are persisted as registry metadata used at runtime.â€

---

### 2ï¸âƒ£ Start GraphQL runtime
```bash
uvicorn app.graphql_runtime_app:app --reload --env-file .env
```
**Purpose:** Starts metadata-driven runtime that builds schema and resolvers dynamically.

**Check health:**
```bash
curl http://127.0.0.1:8000/health
```
âœ… Expected: `{ "ok": true, "db": "ok" }`

**Talking point:** â€œThe runtime loads the registry, constructs GraphQL schema, wires resolvers to Databricks SQL, and verifies connectivity.â€

---

### 3ï¸âƒ£ Export contracts (OpenAPI + SDL)
```bash
make export
```
**Purpose:** Emits per-product contracts to `contracts/`, e.g. `contracts/customer.graphql`, `contracts/payments.openapi.yaml`.

**Talking point:** â€œThese are self-describing contracts â€” standard GraphQL SDL and OpenAPI definitions â€” which external systems or agents can introspect or generate clients from.â€

---

### 4ï¸âƒ£ Register contracts with MCP (mock or real)

**Option A â€” with real MCP**
```bash
export MCP_URL=https://mcp-server/register
make register
```

**Option B â€” local mock MCP**
```bash
python scripts/mock_mcp.py &
export MCP_URL=http://127.0.0.1:9000/register
make register
```
âœ… Expected: `{"status":"ok","name":"customer"}` and `{"status":"ok","name":"payments"}`

**Talking point:** â€œNow the MCP (agent registry) knows about our Data Products and their GraphQL contracts â€” enabling agents or other systems to discover and invoke them dynamically.â€

---

### 5ï¸âƒ£ Query via GraphQL API
```bash
python - <<'PY'
import requests, json
q = """
query {
  list_customers(limit: 5) { customer_id full_name status }
  list_bills(limit: 5) { bill_id amount_due status }
}
"""
r = requests.post("http://127.0.0.1:8000/graphql", json={"query": q})
print(json.dumps(r.json(), indent=2))
PY
```
âœ… Expected output:
```json
{
  "data": {
    "list_customers": [
      {"customer_id": "CUST001", "full_name": "John Doe", "status": "Active"}
    ],
    "list_bills": [
      {"bill_id": "B001", "amount_due": 120.5, "status": "Unpaid"}
    ]
  }
}
```

**Talking point:** â€œThis query runs live against Databricks SQL â€” no hand-written resolvers, all metadata-driven.â€

---

### 6ï¸âƒ£ Bonus â€” Modify spec and regenerate

**Change something in** `dp/telecom.yml` (e.g., add a filter or alias) â†’ then rerun:
```bash
make all
```

**Talking point:** â€œWe can evolve the product definition declaratively. The contracts, schema, and registry all stay consistent automatically.â€

---

## ğŸ§© Services Running During Demo
| Component | Purpose | Port |
|------------|----------|------|
| GraphQL Runtime | Metadata-driven API layer | `8000` |
| Databricks SQL Warehouse | Actual data backend | remote |
| MCP (mock or real) | Contract registry for agents | `9000` |

---

## âœ… Expected Takeaways
- Metadata â†’ API automation: no manual schema or resolver code.
- GraphQL + OpenAPI contracts for interoperability.
- MCP integration for agent discovery.
- Works across domains â€” just change the YAML spec.

---

## ğŸ” Quick Reset Script
```bash
pkill -f "uvicorn .*graphql_runtime_app" || true
uvicorn app.graphql_runtime_app:app --reload --env-file .env &
sleep 2
make all
python - <<'PY'
import requests, json
q = "query { list_customers(limit:2){customer_id full_name} list_bills(limit:2){bill_id amount_due} }"
print(json.dumps(requests.post("http://127.0.0.1:8000/graphql", json={"query": q}).json(), indent=2))
PY
```

---

**End of file â€” demo_flow_runbook.md**

